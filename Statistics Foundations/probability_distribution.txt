PROBABILITY DISTRIBUTION FUNCTIONS

- Probability Distribution Functions describe how probabilities are
  distributed over the possible values of a random variable.

- A random variable is a variable whose values are determined
  by the outcome of a random experiment and is usually denoted by X.


---------------------------------------------------------------------

TYPES OF PROBABILITY DISTRIBUTION FUNCTIONS


1. PROBABILITY MASS FUNCTION (PMF)

- Probability Mass Function is used for discrete random variables.

- PMF is denoted by:
  P(X = x) or f(x)

- It gives the probability that a discrete random variable X
  takes a specific value x.

- Properties of PMF:
  • 0 ≤ P(X = x) ≤ 1
  • Σ P(X = x) = 1 (sum over all possible values)

- Example:
  Rolling a fair die.

  P(X = 1) = P(X = 2) = P(X = 3) =
  P(X = 4) = P(X = 5) = P(X = 6) = 1/6

- In the graph:
  x-axis represents the possible values {1, 2, 3, 4, 5, 6}
  y-axis represents the corresponding probabilities {1/6}


---------------------------------------------------------------------

2. PROBABILITY DENSITY FUNCTION (PDF)

- Probability Density Function is used for continuous random variables.

- PDF is denoted by:
  f(x)

- For continuous random variables:
  P(X = x) = 0

- Probability is represented by the area under the curve
  between two points, not by exact values.

- Probability over an interval:
  P(a ≤ X ≤ b) = ∫[a to b] f(x) dx


PDF PROPERTIES

- Non-negativity:
  f(x) ≥ 0 for all values of x

- Total area under the PDF curve is equal to 1:
  ∫[−∞ to +∞] f(x) dx = 1

- The shape of f(x) depends on the type of distribution.


---------------------------------------------------------------------

CUMULATIVE DISTRIBUTION FUNCTION (CDF)

- Cumulative Distribution Function represents the cumulative
  probability up to a certain value of the random variable.

- It is obtained by accumulating probabilities as we move
  from left to right along the x-axis.

- CDF is denoted by:
  F(x)

- Definition:
  F(x) = P(X ≤ x)

- Range of CDF:
  0 ≤ F(x) ≤ 1

- In the discrete case:
  CDF is a step function.

- Example (discrete):
  P(X ≤ 2) = P(X = 1) + P(X = 2)


---------------------------------------------------------------------

RELATION BETWEEN PDF AND CDF

- CDF is the integral of PDF:
  F(x) = ∫[−∞ to x] f(t) dt

- PDF is the derivative of CDF:
  f(x) = dF(x) / dx

- Interpretation:
  • CDF gives accumulated probability
  • PDF gives density (rate of change of probability)

- Example:
  P(X ≤ 40) = area under the PDF curve up to x = 40


---------------------------------------------------------------------

TYPES OF PROBABILITY DISTRIBUTIONS


1. BERNOULLI DISTRIBUTION (PMF)

- Bernoulli Distribution is the simplest discrete probability distribution.
- It models experiments with exactly two possible outcomes:
  success and failure.

- Parameters:
  p = P(success), where 0 ≤ p ≤ 1
  q = 1 − p
  k ∈ {0, 1}

- Probability Mass Function (PMF):
  P(X = k) = p^k (1 − p)^(1 − k)

  If k = 1 (success): P(X = 1) = p  
  If k = 0 (failure): P(X = 0) = 1 − p


- Examples:
  • Tossing a fair coin:
    P(H) = 0.5, P(T) = 0.5
  • Pass/Fail exam:
    P(pass) = 0.4, P(fail) = 0.6


MEASURES OF CENTRAL TENDENCY

- Mean of Bernoulli Distribution:
  • E(X) = Σ k · P(X = k),  k ∈ {0, 1}
  • E(X) = 0·(1 − p) + 1·p = p

- Median of Bernoulli Distribution:
  • If p < 1/2, Median = 0
  • If p = 1/2, Median ∈ [0, 1]
  • If p > 1/2, Median = 1

- Mode of Bernoulli Distribution:
  • If p > q, Mode = 1
  • If p < q, Mode = 0
  • If p = q, both 0 and 1 are modes


MEASURES OF DISPERSION

- Variance of Bernoulli Distribution:
  • Var(X) = σ² = p · q = p(1 − p)

- Standard Deviation:
  • σ = √(p · q)


2. BINOMIAL DISTRIBUTION (PMF)

- Models the number of successes in n independent Bernoulli trials.
- It is a discrete probability distribution of the number of successes in a sequence
  of n independent experiments, each asking a yes or no question, and each with
  a binary outcome: success or failure.
- A single success/failure experiment is called a Bernoulli trial (or Bernoulli experiment),
  and a sequence of such trials is called a Bernoulli process.
- For a single trial (n = 1), the binomial distribution reduces to the Bernoulli distribution.
- It works with a discrete random variable.
- Every outcome of the experiment is binary.
- The experiment is performed for n trials.
- Example: Tossing a coin 10 times.

Notation: B(n, p)

Parameters:
• n : number of trials, n = 0, 1, 2, 3, ...
• p : probability of success, 0 <= p <= 1
• k : number of successes, k = 0, 1, 2, 3, ..., n

PMF:

• P(X = k) = nCk * p^k * (1 - p)^(n - k)

for k = 0, 1, 2, ..., n where nCk = n! / (k! (n - k)!)

Mean of Binomial Distribution:
• Mean = n * p

Variance of Binomial Distribution:
• Variance = n * p * q
(where q = 1 - p)

Standard Deviation of Binomial Distribution:
• Standard Deviation = √(n * p * q)

Example:

Consider a coin flipped 5 times.
Number of trials (n) = 5
Probability of success (p) = 0.5
What is the probability of getting 3 heads in 5 flips?
Solution :
P(X = 3) = 5C3 * (0.5)^3 * (0.5)²
         = 10 * 0.125 * 0.25
         = 0.3125


3. POISSON DISTRIBUTION (PMF)

- Models the number of events occurring in a fixed interval of time or space.
- It works with a discrete random variable.
- It describes the number of events occurring in a fixed time interval.
- Parameter: λ (lambda) = average rate of occurrence.
- Support: x ∈ {0, 1, 2, 3, ...}

Examples:
- Number of individuals visiting a hospital every hour.
- Number of individuals visiting a bank every hour.

PMF:

P(X = x) = (e^(-λ) * λ^x) / x!

for x = 0, 1, 2, ...

Mean of Poisson Distribution:
• Mean = E(X) = λ * t


4. NORMAL / GAUSSIAN DISTRIBUTION (PDF)

- A continuous probability distribution with a bell-shaped curve.
- It is defined by mean (μ) and standard deviation (σ).
- It is a symmetric distribution.
- For a normal distribution:
  Mean = Median = Mode.

Notation:
  N(μ, σ²)

Parameters:
- μ ∈ R        (mean)
- σ² ∈ R, σ² > 0   (variance)

- As σ² increases, the spread of the data increases.

PDF:

f(x) = (1 / (σ * sqrt(2π))) * exp( - (x - μ)² / (2σ²) )

Mean of Normal / Gaussian Distribution:
• Mean = μ

Variance of Normal / Gaussian Distribution:
• Variance = σ²

Standard Deviation of Normal / Gaussian Distribution:
• Standard Deviation = σ

Empirical Rule of Normal / Gaussian Distribution
(68 - 95 - 99.7 rule):

P(μ - σ <= X <= μ + σ)     ≈ 68%
P(μ - 2σ <= X <= μ + 2σ)   ≈ 95%
P(μ - 3σ <= X <= μ + 3σ)   ≈ 99.7%


5. STANDARD NORMAL DISTRIBUTION AND Z-SCORE

- Let X = {1, 2, 3, 4, 5}, μ = 3 and σ = 1.414.
- If the above distribution is converted such that μ = 0 and σ = 1,
  then the resulting distribution is called the Standard Normal Distribution.
- In order to convert a normal distribution to a standard normal distribution,
  we use the Z-score.

Z-score formula:

Z = (xi - μ) / σ

- In short, the standard normal distribution is denoted as:
  N(0, 1)

Example:
How many standard deviations is 4.25 away from the mean, if
μ = 4 and σ = 1 ?

Solution:
Z = (4.25 - 4) / 1
Z = 0.25


Usage of Z-score:

- To bring features to the same scale, standardization is used.
- After standardization, most values lie in the range [-3, +3].
- Z-score is used in clustering algorithms, linear regression and
  logistic regression.



6. UNIFORM DISTRIBUTION

- All outcomes are equally likely.
- Uniform distribution can be discrete (PMF) or continuous (PDF).


a) CONTINUOUS UNIFORM DISTRIBUTION

- The continuous uniform distribution (also called rectangular distribution)
  is a family of symmetric probability distributions.
- It describes an experiment where the outcome lies between fixed bounds.
- The bounds are defined by the parameters a and b, which represent the
  minimum and maximum values.

Notation:
• U(a, b)

Parameter:
• -∞ < a < b < ∞

PDF:

• f(x) = 1 / (b - a),    if x ∈ [a, b]
• f(x) = 0,              otherwise

CDF:

• F(x) = 0,                       if x < a
• F(x) = (x - a) / (b - a),       if a <= x <= b
• F(x) = 1,                       if x > b

Mean:
• (a + b) / 2

Median:
• (a + b) / 2

Variance:
• (b - a)^2 / 12


Example:

The number of candies sold daily at a shop is uniformly distributed
with a minimum of 10 candies and a maximum of 40 candies.

Find the probability that the daily sales fall between 15 and 30.

Solution:

P(15 <= X <= 30) = (30 - 15) / (40 - 10)
                 = 15 / 30
                 = 0.5



b) DISCRETE UNIFORM DISTRIBUTION

- A discrete uniform distribution is a symmetric probability distribution in which
  a finite number of outcomes are equally likely.
- Each outcome has the same probability.

If there are n possible outcomes, then: P(X = x) = 1 / n

Example:
Rolling a fair die.

Notation:
• U(a, b)

Parameter:
• a,b where b >= a

PMF:
• 1/n

Mean:
• (a+b)/2

Median:
• (a+b)/2



7. LOG-NORMAL DISTRIBUTION (PDF)

- A continuous probability distribution in which the logarithm of the
  random variable follows a normal distribution.
- If a random variable X is log-normally distributed, then
  Y = ln(X) follows a normal distribution.
- Equivalently, if Y follows a normal distribution, then
  X = exp(Y) follows a log-normal distribution.
- Log-normal distribution is a right-skewed distribution.
- Log-normal data becomes approximately normal after applying
  a logarithmic transformation (can be verified using a Q–Q plot).

Examples:
- Wealth distribution in the world.
- Length of comments in online discussion forums.
- Dwell time on online articles.



8. POWER LAW DISTRIBUTION

- In statistics, a power law is a functional relationship between two quantities,
  where one quantity varies as a power of another.
- A relative change in one quantity results in a proportional relative change
  in the other quantity raised to a constant exponent.
- The relationship is independent of the initial size of the quantities.

General form:

P(X = x) ∝ x^(-α),   where α > 0

- It is commonly associated with the 80–20 rule (Pareto principle).

Examples:
- In IPL, 20% of players contribute to 80% of wins.
- 80% of wealth is owned by 20% of the population.
- 80% of the total oil is held by 20% of the nations.
- Frequencies of words in most languages.
- 20% of major defects cause about 80% of the software problems.

- Power-law distributed data can often be made closer to a normal distribution
  using transformations such as the Box–Cox transform.
- When data follows an 80–20 type power-law behaviour, it is commonly
  referred to as following a Pareto-type distribution.



9. PARETO DISTRIBUTION

- A continuous probability distribution used to model phenomena
  that follow the 80–20 rule.
- It is a special case of power-law distribution.

Parameters:
- xm > 0   (scale or minimum value)
- α > 0    (shape parameter)

Support:
x ≥ xm

PDF:

f(x) = α * xm^α / x^(α + 1),    for x ≥ xm

Mean (for α > 1):

Mean = α * xm / (α - 1)

Variance (for α > 2):

Variance = (α * xm^2) / ((α - 1)^2 * (α - 2))

- Pareto distribution is right-skewed and heavy-tailed.

Examples:
- 80% of certain project is done by 20% of the team
- 80% of defects can be solved if we solve 20% of main defects.
- File sizes on the internet.


---------------------------------------------------------------------

CENTRAL LIMIT THEOREM

- The Central Limit Theorem (CLT) is based on the concept of a sampling distribution.
- A sampling distribution is the probability distribution of a statistic (such as the sample mean)
  obtained from a large number of samples drawn from the same population.

- The Central Limit Theorem states that the sampling distribution of the sample mean
  will be approximately normally distributed, provided the sample size is sufficiently large.

- This holds regardless of whether the original population distribution is normal,
  Poisson, binomial, or any other distribution (with finite mean and variance).

- If the population (random variable) follows a normal distribution, then the
  sampling distribution of the sample mean is normal for any sample size.

- If the population does not follow a normal (Gaussian) distribution, then for
  sufficiently large sample size (commonly n >= 30), the sampling distribution of
  the sample mean is approximately normal.

---------------------------------------------------------------------

ESTIMATES

- An estimate is a numerical value calculated from sample data and is used to
  estimate an unknown population parameter.

TYPES OF ESTIMATES:

1) POINT ESTIMATE

- A single numerical value used to estimate an unknown population parameter.
- Example:
  The sample mean is a point estimate of the population mean.

2) INTERVAL ESTIMATE

- A range of values used to estimate an unknown population parameter.
- This range is called a confidence interval.
 